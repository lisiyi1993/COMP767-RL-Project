{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, trange\n",
    "from IPython import display\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the core modules\n",
    "\n",
    "class ConvStack(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements the conv_stack module as described in figure 6\n",
    "    \"\"\"\n",
    "    def __init__(self, k1, c1, k2, c2, k3, c3):\n",
    "        super(ConvStack, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=c1, kernel_size=k1, padding=(k1-1)//2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=c1, out_channels=c2, kernel_size=k2, padding=(k2-1)//2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=c2, out_channels=c3, kernel_size=k3, padding=(k3-1)//2)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        if not torch.is_tensor(X):\n",
    "            X = torch.from_numpy(X).type(torch.FloatTensor)\n",
    "            \n",
    "        conv1_X = self.conv1(X)\n",
    "        conv1_relu = F.relu(conv1_X)\n",
    "        \n",
    "        conv2_X = self.conv2(conv1_X)\n",
    "        conv2_relu = F.relu(conv2_X + conv1_relu)\n",
    "        \n",
    "        conv3_X = self.conv3(conv2_relu)\n",
    "        \n",
    "        return conv3_X\n",
    "    \n",
    "    \n",
    "class ResConv(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements the res_conv module as described in figure 7 in the paper\n",
    "    \"\"\"\n",
    "    def __init__(self, use_extra_convolution=True):\n",
    "        super(ResConv, self).__init__()\n",
    "        self.use_extra_convolution = use_extra_convolution\n",
    "        self.extra_conv = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=1)\n",
    "        \n",
    "        if use_extra_convolution:\n",
    "            conv1_in_channels = 64\n",
    "        else:\n",
    "            conv1_in_channels = 3\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=conv1_in_channels, out_channels=32, kernel_size=3, padding=(3-1)//2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=5, padding=(5-1)//2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=(3-1)//2)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        if not torch.is_tensor(X):\n",
    "            X = torch.from_numpy(X).type(torch.FloatTensor)\n",
    "            \n",
    "        if self.use_extra_convolution:\n",
    "            c = self.extra_conv(X)\n",
    "        else:\n",
    "            c = X\n",
    "        \n",
    "        conv1_relu = F.relu(self.conv1(c))\n",
    "        conv2_relu = F.relu(self.conv2(conv1_relu))\n",
    "        rc3 = self.conv3(conv2_relu)\n",
    "        rc = c + rc3\n",
    "        return rc\n",
    "    \n",
    "\n",
    "class StateTransitionModule(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements the state transition function g(s,z,a) as described in figure 9 in the paper\n",
    "    An action, a state and a latent variable at time t-1 is transitioned to \n",
    "    a state at time t.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(StateTransitionModule, self).__init__()\n",
    "        self.res_conv1 = ResConv()\n",
    "        self.res_conv2 = ResConv()\n",
    "        \n",
    "    def pool_inject(self, X):\n",
    "        \"\"\"\n",
    "        Implements the pool & inject module as described in figure 8 in the paper\n",
    "        \"\"\"\n",
    "        if not torch.is_tensor(X):\n",
    "            X = torch.from_numpy(X).type(torch.FloatTensor)\n",
    "\n",
    "        height, width = X.shape[2:]\n",
    "        pooled = F.max_pool2d(X, kernel_size=(height, width), stride=(1, 1))\n",
    "        tiled = pooled.expand(X.shape)\n",
    "        pi = torch.cat([tiled, X], axis=1) # concat on the Color channel\n",
    "        return pi\n",
    "    \n",
    "    def forward(self, a, s, z):      \n",
    "        concat = torch.cat([a, s, z], 1)\n",
    "        rc1_relu = F.relu(self.res_conv1(concat))\n",
    "        pi = self.pool_inject(rc1_relu)\n",
    "        s_next = self.res_conv2(pi)\n",
    "        \n",
    "        return s_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InitialModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InitialModule, self).__init__()\n",
    "        self.conv_stack1 = ConvStack(3, 16, 5, 16, 3, 64)\n",
    "        \n",
    "    def forward(self, o):\n",
    "        return self.conv_stack1(o)\n",
    "        \n",
    "\n",
    "class ObservationEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ObservationEncoder, self).__init__()\n",
    "        self.conv_stack1 = ConvStack(3, 16, 5, 16, 3, 64)\n",
    "        self.conv_stack2 = ConvStack(3, 32, 5, 32, 3, 64)\n",
    "        \n",
    "    def forward(self, o):\n",
    "        std1 = o.view(o.shape[0], -1, o.shape[2]//4, o.shape[3]//4)\n",
    "        cs1 = self.conv_stack1(std1)\n",
    "        std2 = std1.view(std1.shape[0], -1, std1.shape[2]//2, std1.shape[3]//2)\n",
    "        cs2 = self.conv_stack2(std2)\n",
    "        e = F.relu(cs2)\n",
    "        return e\n",
    "    \n",
    "class ObservationDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ObservationDecoder, self).__init__()\n",
    "        self.conv_stack1 = ConvStack(1, 32, 5, 32, 3, 64)\n",
    "        self.conv_stack2 = ConvStack(3, 64, 3, 64, 1, 48)\n",
    "        \n",
    "    def forward(self, s, z):\n",
    "        concat = torch.cat([s, z], 1) \n",
    "        cs1 = self.conv_stack1(concat)\n",
    "        dts1 = cs1.view(cs1.shape[0], -1, int(cs1.shape[2]*2), int(cs1.shape[3]*2))\n",
    "        cs2 = self.conv_stack2(dts1)\n",
    "        dts2 = cs2.view(cs2.shape[0], -1, int(cs2.shape[2]*4), int(cs2.shape[3]*4))\n",
    "        \n",
    "        return dts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
